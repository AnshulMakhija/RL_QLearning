{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da8ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grid():\n",
    "    def __init__(self,size=5):\n",
    "        self.size = size\n",
    "        self.start = (0,0)\n",
    "        self.goal = (4,4)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.agent_pos = self.start\n",
    "        return self.agent_pos\n",
    "    \n",
    "    def state(self):\n",
    "        return self.agent_pos\n",
    "    \n",
    "    def goal_state(self):\n",
    "        return self.goal\n",
    "    \n",
    "    def step(self, action):\n",
    "        x,y = self.agent_pos\n",
    "        \n",
    "        if action == 'up':\n",
    "            x = max(0, x-1)\n",
    "            \n",
    "        elif action == 'down':\n",
    "            x = min(self.size-1, x+1)\n",
    "            \n",
    "        elif action == 'left':\n",
    "            y = max(0, y-1)\n",
    "            \n",
    "        elif action == 'right':\n",
    "            y = min(self.size-1, y+1)\n",
    "            \n",
    "        self.agent_pos = (x,y)\n",
    "        \n",
    "        reward = 10 if self.agent_pos == self.goal else -1\n",
    "        done = self.agent_pos == self.goal\n",
    "        return self.agent_pos, reward, done\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f831cb8",
   "metadata": {},
   "source": [
    "# Random Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef0b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Grid()\n",
    "actions = ['up', 'down', 'left', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626ef371",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfffb9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Step 1: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 2: Action: right, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 3: Action: up, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 4: Action: up, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 5: Action: down, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 6: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 7: Action: down, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 8: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 9: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 10: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 11: Action: up, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 12: Action: down, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 13: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 14: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 15: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 16: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 17: Action: right, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 18: Action: right, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 19: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 20: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 21: Action: left, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 22: Action: right, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 23: Action: left, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 24: Action: right, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 25: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 26: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 27: Action: right, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 28: Action: down, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 29: Action: up, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 30: Action: down, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 31: Action: up, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 32: Action: down, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 33: Action: right, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 34: Action: down, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 35: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 36: Action: left, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 37: Action: up, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 38: Action: right, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 39: Action: down, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 40: Action: left, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 41: Action: down, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 42: Action: right, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 43: Action: up, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 44: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 45: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 46: Action: left, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 47: Action: up, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 48: Action: down, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 49: Action: down, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 50: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 51: Action: right, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 52: Action: up, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 53: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 54: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 55: Action: right, State: (0, 0) -> (4, 4), Reward: 10\n",
      "Episode 1 finished in 55 steps with total reward: -44\n",
      "\n",
      "Episode 2\n",
      "Step 1: Action: right, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 2: Action: down, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 3: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 4: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 5: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 6: Action: down, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 7: Action: down, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 8: Action: up, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 9: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 10: Action: right, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 11: Action: right, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 12: Action: up, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 13: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 14: Action: up, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 15: Action: up, State: (0, 0) -> (0, 4), Reward: -1\n",
      "Step 16: Action: down, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 17: Action: down, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 18: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 19: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 20: Action: down, State: (0, 0) -> (3, 4), Reward: -1\n",
      "Step 21: Action: left, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 22: Action: left, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 23: Action: left, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 24: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 25: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 26: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 27: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 28: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 29: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 30: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 31: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 32: Action: right, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 33: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 34: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 35: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 36: Action: down, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 37: Action: up, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 38: Action: down, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 39: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 40: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 41: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 42: Action: down, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 43: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 44: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 45: Action: up, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 46: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 47: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 48: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 49: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 50: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 51: Action: down, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 52: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 53: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 54: Action: down, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 55: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 56: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 57: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 58: Action: right, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 59: Action: left, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 60: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 61: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 62: Action: right, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 63: Action: up, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 64: Action: right, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 65: Action: right, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 66: Action: left, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 67: Action: right, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 68: Action: right, State: (0, 0) -> (3, 4), Reward: -1\n",
      "Step 69: Action: down, State: (0, 0) -> (4, 4), Reward: 10\n",
      "Episode 2 finished in 69 steps with total reward: -58\n",
      "\n",
      "Episode 3\n",
      "Step 1: Action: right, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 2: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 3: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 4: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 5: Action: right, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 6: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 7: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 8: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 9: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 10: Action: right, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 11: Action: up, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 12: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 13: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 14: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 15: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 16: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 17: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 18: Action: right, State: (0, 0) -> (0, 1), Reward: -1\n",
      "Step 19: Action: down, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 20: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 21: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 22: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 23: Action: down, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 24: Action: right, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 25: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 26: Action: up, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 27: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 28: Action: left, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 29: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 30: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 31: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 32: Action: right, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 33: Action: right, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 34: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 35: Action: left, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 36: Action: up, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 37: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 38: Action: down, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 39: Action: down, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 40: Action: right, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 41: Action: up, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 42: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 43: Action: right, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 44: Action: right, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 45: Action: left, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 46: Action: down, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 47: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 48: Action: left, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 49: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 50: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 51: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 52: Action: up, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 53: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 54: Action: right, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 55: Action: up, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 56: Action: up, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 57: Action: right, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 58: Action: down, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 59: Action: left, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 60: Action: up, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 61: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 62: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 63: Action: down, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 64: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 65: Action: down, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 66: Action: right, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 67: Action: down, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 68: Action: down, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 69: Action: left, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 70: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 71: Action: up, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 72: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 73: Action: left, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 74: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 75: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 76: Action: up, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 77: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 78: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 79: Action: up, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 80: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 81: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 82: Action: right, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 83: Action: right, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 84: Action: up, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 85: Action: right, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 86: Action: up, State: (0, 0) -> (0, 4), Reward: -1\n",
      "Step 87: Action: up, State: (0, 0) -> (0, 4), Reward: -1\n",
      "Step 88: Action: left, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 89: Action: down, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 90: Action: left, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 91: Action: down, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 92: Action: left, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 93: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 94: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 95: Action: down, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 96: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 97: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 98: Action: up, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 99: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 100: Action: right, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 101: Action: right, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 102: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 103: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 104: Action: left, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 105: Action: down, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 106: Action: right, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 107: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 108: Action: up, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 109: Action: left, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 110: Action: left, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 111: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 112: Action: up, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 113: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 114: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 115: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 116: Action: right, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 117: Action: left, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 118: Action: up, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 119: Action: right, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 120: Action: left, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 121: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 122: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 123: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 124: Action: down, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 125: Action: up, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 126: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 127: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 128: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 129: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 130: Action: left, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 131: Action: up, State: (0, 0) -> (0, 0), Reward: -1\n",
      "Step 132: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 133: Action: left, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 134: Action: down, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 135: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 136: Action: down, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 137: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 138: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 139: Action: right, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 140: Action: right, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 141: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 142: Action: up, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 143: Action: right, State: (0, 0) -> (3, 4), Reward: -1\n",
      "Step 144: Action: up, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 145: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 146: Action: down, State: (0, 0) -> (3, 4), Reward: -1\n",
      "Step 147: Action: up, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 148: Action: down, State: (0, 0) -> (3, 4), Reward: -1\n",
      "Step 149: Action: down, State: (0, 0) -> (4, 4), Reward: 10\n",
      "Episode 3 finished in 149 steps with total reward: -138\n",
      "\n",
      "Episode 4\n",
      "Step 1: Action: down, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 2: Action: right, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 3: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 4: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 5: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 6: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 7: Action: right, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 8: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 9: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 10: Action: up, State: (0, 0) -> (1, 0), Reward: -1\n",
      "Step 11: Action: right, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 12: Action: right, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 13: Action: left, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 14: Action: right, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 15: Action: down, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 16: Action: up, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 17: Action: up, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 18: Action: right, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 19: Action: down, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 20: Action: right, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 21: Action: down, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 22: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 23: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 24: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 25: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 26: Action: right, State: (0, 0) -> (2, 4), Reward: -1\n",
      "Step 27: Action: left, State: (0, 0) -> (2, 3), Reward: -1\n",
      "Step 28: Action: up, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 29: Action: right, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 30: Action: right, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 31: Action: right, State: (0, 0) -> (1, 4), Reward: -1\n",
      "Step 32: Action: up, State: (0, 0) -> (0, 4), Reward: -1\n",
      "Step 33: Action: left, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 34: Action: left, State: (0, 0) -> (0, 2), Reward: -1\n",
      "Step 35: Action: right, State: (0, 0) -> (0, 3), Reward: -1\n",
      "Step 36: Action: down, State: (0, 0) -> (1, 3), Reward: -1\n",
      "Step 37: Action: left, State: (0, 0) -> (1, 2), Reward: -1\n",
      "Step 38: Action: left, State: (0, 0) -> (1, 1), Reward: -1\n",
      "Step 39: Action: down, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 40: Action: left, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 41: Action: down, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 42: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 43: Action: up, State: (0, 0) -> (2, 0), Reward: -1\n",
      "Step 44: Action: down, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 45: Action: down, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 46: Action: left, State: (0, 0) -> (4, 0), Reward: -1\n",
      "Step 47: Action: right, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 48: Action: up, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 49: Action: left, State: (0, 0) -> (3, 0), Reward: -1\n",
      "Step 50: Action: right, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 51: Action: right, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 52: Action: down, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 53: Action: up, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 54: Action: up, State: (0, 0) -> (2, 2), Reward: -1\n",
      "Step 55: Action: down, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 56: Action: left, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 57: Action: up, State: (0, 0) -> (2, 1), Reward: -1\n",
      "Step 58: Action: down, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 59: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 60: Action: right, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 61: Action: right, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 62: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 63: Action: up, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 64: Action: left, State: (0, 0) -> (3, 2), Reward: -1\n",
      "Step 65: Action: left, State: (0, 0) -> (3, 1), Reward: -1\n",
      "Step 66: Action: down, State: (0, 0) -> (4, 1), Reward: -1\n",
      "Step 67: Action: right, State: (0, 0) -> (4, 2), Reward: -1\n",
      "Step 68: Action: right, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 69: Action: up, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 70: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 71: Action: up, State: (0, 0) -> (3, 3), Reward: -1\n",
      "Step 72: Action: down, State: (0, 0) -> (4, 3), Reward: -1\n",
      "Step 73: Action: right, State: (0, 0) -> (4, 4), Reward: 10\n",
      "Episode 4 finished in 73 steps with total reward: -62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for episode in range(episodes):\n",
    "    state = environment.reset()\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    print(f\"Episode {episode+1}\")\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = random.choice(actions)\n",
    "        next_state, reward, done = environment.step(action)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        print(f\"Step {steps}: Action: {action}, State: {state} -> {next_state}, Reward: {reward}\")\n",
    "        \n",
    "    print(f\"Episode {episode+1} finished in {steps} steps with total reward: {total_reward}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60406a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
